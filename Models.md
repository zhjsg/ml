---
layout: default
---

[BACK](./)

## I Regression

1. Simple Linear Regression 
```
A. The weighted sum of inputs is calculated
B. The Bias is added
C. The result is fed to an activation function
D. Specific Neuron is activated
```

1. Multiple Linear Regression

1. Polynomial Linear Regression

1. Support Vector Regression

1. Decision Tree Regression

1. Random Forest Regression

1. Ridge Regression

1. Lasso Regression

## II Classification

1. Logistic Regression

1. K Nearest Neighbours

1. Support Vector Machine

1. Kernal SVM

1. Naive Bayes

1. Decision Tree Classification

1. Random Forest Classification

## III Clustering

1. K-Means

1. Hierarchical Clustering

## IV Association Rule Learning

1. Apriori

1. Eclat

## V Reinforcement Learning

1. Upper Confidence Bound

1. Thompson Sampling

## VI Natural Language Processing

1. Bag of words

## VII Deep Learning

1. Artificial Neural Network

1. Convolutional Neural Network

1. Recurrenct Neural Network

1. Self-Organizing Maps

1. Boltzmann Machines

1. AutoEncoders

## VIII Dimensionality Reduction

1. Principal Component Analysis

1. Latent Dirichlet allocation

1. Kernal PCA

## IX Boosting

1. AdaBoost

1. Gradient Boosting

1. XGBoost

* * *

Reference:

1. [https://www.superdatascience.com/blogs/regression-classification-simple-linear-regression-step-1](https://www.superdatascience.com/blogs/regression-classification-simple-linear-regression-step-1)
1. [https://medium.com/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff](https://medium.com/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff)
1. [https://www.kaggle.com/pankeshpatel/polynomial-linear-regression-tutorial](https://www.kaggle.com/pankeshpatel/polynomial-linear-regression-tutorial)
1. [https://www.nosimpler.me/polynomial-regression/](https://www.nosimpler.me/polynomial-regression/)
1. [https://www.saedsayad.com/support_vector_machine_reg.htm](https://www.saedsayad.com/support_vector_machine_reg.htm)
1. [https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054](https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054)
1. [https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f](https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f)
1. [https://www.slideshare.net/kaz_yos/visual-explanation-of-ridge-regression-and-lasso](https://www.slideshare.net/kaz_yos/visual-explanation-of-ridge-regression-and-lasso)
1. [https://www.saedsayad.com/logistic_regression.htm](https://www.saedsayad.com/logistic_regression.htm)
1.[https://towardsdatascience.com/knn-k-nearest-neighbors-1-a4707b24bd1d](https://towardsdatascience.com/knn-k-nearest-neighbors-1-a4707b24bd1d)
1.[https://www.saedsayad.com/support_vector_machine.htm](https://www.saedsayad.com/support_vector_machine.htm)
1.[https://stats.stackexchange.com/questions/422902/what-are-kernels-in-support-vector-machine](https://stats.stackexchange.com/questions/422902/what-are-kernels-in-support-vector-machine)
1.[https://www.hackerearth.com/blog/developers/simple-tutorial-svm-parameter-tuning-python-r/](https://www.hackerearth.com/blog/developers/simple-tutorial-svm-parameter-tuning-python-r/)
1.[https://www.globalsoftwaresupport.com/naive-bayes-classifier-explained-step-step/](https://www.globalsoftwaresupport.com/naive-bayes-classifier-explained-step-step/)
1.[https://www.jeremyjordan.me/decision-trees/](https://www.jeremyjordan.me/decision-trees/)
16.[https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d](https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d)
17.[http://sherrytowers.com/2013/10/24/k-means-clustering/](http://sherrytowers.com/2013/10/24/k-means-clustering/)
18.[https://www.displayr.com/what-is-hierarchical-clustering/](https://www.displayr.com/what-is-hierarchical-clustering/)
19.[https://www.sites.google.com/site/getallcodesyouwant/data-mining/apriori-algorithm](https://www.sites.google.com/site/getallcodesyouwant/data-mining/apriori-algorithm)
20.[https://www.slideshare.net/wanaezwani/apriori-and-eclat-algorithm-in-association-rule-mining](https://www.slideshare.net/wanaezwani/apriori-and-eclat-algorithm-in-association-rule-mining)
21.[]()
22.[]()
23.[]()
24.[]()
25.[]()
26.[]()


[BACK](./)
