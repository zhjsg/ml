---
layout: default
---

[BACK](./)

Reference:

1. [https://www.certifiedanalytics.org](https://www.certifiedanalytics.org)

## I Resources
```
AB testing:
www.evanmiller.org/ab-testing/chi-squared.html

Chi-Squared testing:
vassarstats.net/newcs.html

Function graphs:
Rechneronline.de/function-graphs/

Normal distribution
onlinestatbook.com/stat_sim/sampling_dist/index.html

SVR
Https://core.ac.uk/download/pdf/81523322.pdf

UCI repository
https://archive.ics.uci.edu/ml/index.php

Colab Link:
https://colab.research.google.com/drive/1EBtaT0q_yHlfP8JrUdUcEKwD7J48_5Ya

TensorFlow
https://www.youtube.com/watch?v=HcqpanDadyQ&list=PLIivdWyY5sqJdmVMjLI8iCul14XkTRosn

Kernel SVM Functions:
Mlkernels.readthedocs.io/en/latest/krnelfunctions.html

https://app3.unit4hrms.com/PWC/JRI/web/Epay/Payslip_List.aspx
http://app3.unit4hrms.com/PWC/JRI/web/login.aspx

The Neuron
http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf

Activation Function
http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf

Neural Networks
http://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications
http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf
https://www.3blue1brown.com/neural-networks

Gradient Descent
https://iamtrask.github.io/2015/07/27/python-network-part2/
http://neuralnetworksanddeeplearning.com/chap2.html

Convolutional Neural Networks
http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf
http://cs.nju.edu.cn/wujx/paper/CNN.pdf

ReLU layer
https://arxiv.org/pdf/1609.04112.pdf
https://arxiv.org/pdf/1502.01852.pdf

Max pooling
http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf
scs.ryerson.ca/~aharley/vis/conv/flat.html
https://adeshpande3.github.io/the-9-deep-learning-papers-you-need-to-know-about.html

Cross-Entropy
https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/
https://peterroelants.github.io/posts/neural_network_implementation_intermezzo02/

BERT colab:
https://colab.research.google.com/drive/1NvffaS8wAmCPEjU6R_tF3b8FxkdVhFR5

Natural Language Processing (NLP) with BERT 
https://www.udemy.com/course/natural-language-processing-with-bert/learn/lecture/18889310#overview
https://sdsclub.com/bert-google-nlp-algorithm/
```
Statistical definition of p value
```
P value is “The probability” for the “Null Hypothesis” to be “True”
P value (any value from 0 to 1)
Low p -> reject null
High p -> fail to reject null
```
Null Hypothesis (H0)
```
Treats Everything same
Treats Everything equal
No difference between groups
```
7 Steps of Machine Learning
```
1. Gathering Data
2. Preparing that Data
3. Choosing a Model
4. Training
5. Evaluation
6. Hyperparameter Tuning
7. Prediction
```
Artificially Intelligent
```
1. Generalized learning
2. Reasoning
3. Problem solving

AI provide machine to adapt, reason and provide solutions.
``` 

Data Structures in Python
<table>
  <tr>
    <th>Dimension</th> <th>Homogenous</th> <th>Heterogeneous</th>
  </tr>
  <tr>
    <td>1D</td> <td>Array</td> <td>Tuple, Set</td>
  </tr>
  <tr>
    <td>2D</td> <td></td> <td></td>
  </tr>
  <tr>
    <td>nD</td> <td></td> <td>List, Dictionary</td>
  </tr>
</table>

Data Structures in R
<table>
  <tr>
    <th>Dimension</th> <th>Homogenous</th> <th>Heterogeneous</th>
  </tr>
  <tr>
    <td>1D</td> <td>Vector</td> <td>List</td>
  </tr>
  <tr>
    <td>2D</td> <td>Matrix</td> <td>Dataframe</td>
  </tr>
  <tr>
    <td>nD</td> <td>Array</td> <td></td>
  </tr>
</table>

Four main types of analytics
<table>
  <tr>
    <td>Descriptive analytics</td> <td>What happend?</td> <td>JDA</td>
  </tr>
  <tr>
    <td>Diagnostic analytics</td> <td>Why did it happen?</td> <td>SDA</td>
  </tr>
  <tr>
    <td>Predictive analytics</td> <td>What will happen?</td> <td>JDS</td>
  </tr>
  <tr>
    <td>Prescriptive analytics</td> <td>How to make it happen?</td> <td>SDS</td>
  </tr>
</table>
  

## II ...

1. ...
1. ...
1. ...

## III ...

1. ...
1. ...
1. ...

## IV ...

1. ...
1. ...
1. ...
1. ...

## V ...

1. ...
1. ...
1. ...

* * *

[BACK](./)
